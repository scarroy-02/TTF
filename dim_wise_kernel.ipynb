{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gudhi as gd\n",
    "import numpy as np\n",
    "from gudhi.representations import kernel_methods\n",
    "import networkx as nx\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_output(mat_train,mat_test,y_train,y_test):\n",
    "    # Using SVM\n",
    "\n",
    "    svm_classifier = SVC(kernel='precomputed')\n",
    "    svm_classifier.fit(mat_train, y_train)\n",
    "\n",
    "    # y_pred = svm_classifier.predict(mat_test)\n",
    "\n",
    "    accuracy = svm_classifier.score(mat_test, y_test)\n",
    "    print(\"Accuracy using SVM : \", accuracy)\n",
    "\n",
    "    # print(classification_report(y_test,y_pred))\n",
    "\n",
    "def logistic_output(mat_train,mat_test,y_train,y_test):\n",
    "\n",
    "    # Using logistic regression\n",
    "\n",
    "    klr = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "    klr.kernel = 'precomputed'\n",
    "\n",
    "    klr.fit(mat_train,y_train)\n",
    "\n",
    "    # y_pred = klr.predict(mat_test)\n",
    "\n",
    "    accuracy = klr.score(mat_test, y_test)\n",
    "    print(\"Accuracy using Logistic Regression : \", accuracy)\n",
    "\n",
    "    # print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_testing(v,e,n_cluster,n_copies,wp,pers_dim):\n",
    "\n",
    "    sparsity = 2 * e / (v * (v + 1))\n",
    "    print(f\"Sparsity : {sparsity}\")\n",
    "\n",
    "    class_graphs = [nx.gnm_random_graph(v,e) for _ in range(n_cluster)]\n",
    "    for G in class_graphs:\n",
    "        for (u,v) in G.edges():\n",
    "            G.edges[u,v]['time'] = random.randint(0,100)\n",
    "\n",
    "    all_graphs = [change_graph(grph,wp) for grph in class_graphs for _ in range(n_copies)]\n",
    "\n",
    "    label = [i for i in range(n_cluster) for _ in range(n_copies)]\n",
    "\n",
    "    Lw = []\n",
    "    for i in all_graphs:\n",
    "        Lw += [assign_weights(i)]\n",
    "\n",
    "    Lwe = []\n",
    "    for i in Lw:\n",
    "        Lwe += [adj_fillinf(i)]\n",
    "\n",
    "    input_diag_trial = []\n",
    "\n",
    "    # Trying Gudhi dimension-wise\n",
    "    for Ad in tqdm(Lwe):\n",
    "        skeleton = gd.RipsComplex(distance_matrix=Ad, max_edge_length=2000)\n",
    "        simplex_tree = skeleton.create_simplex_tree(max_dimension=pers_dim+2)\n",
    "        barcode = simplex_tree.persistence()\n",
    "        input_diag_trial.append(simplex_tree.persistence_intervals_in_dimension(pers_dim))\n",
    "\n",
    "    for i in range(n_cluster*n_copies):\n",
    "        input_diag_trial[i][input_diag_trial[i] == np.inf] = 10000\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_diag_trial, label, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_combined = (X_train + X_test)\n",
    "\n",
    "    # Write the diagrams to a file\n",
    "    with open('persistent_diagrams.txt', 'w') as f:\n",
    "        for diagram in X_combined:\n",
    "            np.savetxt(f, diagram, fmt='%.2f')\n",
    "            f.write('\\n')\n",
    "\n",
    "    print(\"Persistence diagrams file written\")\n",
    "\n",
    "    def compute_kernel_matrix():\n",
    "        # Call the C++ program\n",
    "        result = subprocess.run(['./kmp'], check=True)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise Exception(\"C++ program failed to run.\")\n",
    "        \n",
    "        # Load the kernel matrix from the CSV file\n",
    "        kernel_matrix = np.loadtxt('kernel_matrix.csv', delimiter=',')\n",
    "        return kernel_matrix\n",
    "    \n",
    "    # Compute the kernel matrix using the C++ program\n",
    "    pssk_matrix_combined = compute_kernel_matrix()\n",
    "\n",
    "    print(\"Kernelization complete\")\n",
    "\n",
    "    # Split the kernel matrix into train and test parts\n",
    "    num_train = len(X_train)\n",
    "    pssk_matrix_train = pssk_matrix_combined[:num_train, :num_train]\n",
    "    pssk_matrix_test = pssk_matrix_combined[num_train:, :num_train]\n",
    "\n",
    "    # Weighted Gaussian Kernel\n",
    "\n",
    "    # pwgk = kernel_methods.PersistenceWeightedGaussianKernel(bandwidth=1)\n",
    "    # pwgk_matrix_combined = pwgk.fit_transform(X_combined)\n",
    "    # pwgk_matrix_train = pwgk_matrix_combined[:num_train, :num_train]\n",
    "    # pwgk_matrix_test = pwgk_matrix_combined[num_train:, :num_train]\n",
    "\n",
    "    print(\"Using Scale Space Kernel : \")\n",
    "    svm_output(pssk_matrix_train,pssk_matrix_test,y_train,y_test)\n",
    "    logistic_output(pssk_matrix_train,pssk_matrix_test,y_train,y_test)\n",
    "\n",
    "    # print(\"Using Weighted Gaussian Kernel : \")\n",
    "    # svm_output(pwgk_matrix_train,pwgk_matrix_test,y_train,y_test)\n",
    "    # logistic_output(pwgk_matrix_train,pwgk_matrix_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 639.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence diagrams file written\n",
      "Reading complete\n",
      "Time taken: 0.0311278 seconds\n",
      "Kernelization complete\n",
      "Time taken: 11.8143 seconds\n",
      "Kernelization complete\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9666666666666667\n",
      "Accuracy using Logistic Regression :  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "new_testing(50,1000,3,100,0.05,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test_results(v,e,n_cluster,n_copies,wp):\n",
    "    sparsity = 2 * e / (v * (v + 1))\n",
    "\n",
    "    class_graphs = [nx.gnm_random_graph(v,e) for _ in range(n_cluster)]\n",
    "    for G in class_graphs:\n",
    "        for (u,v) in G.edges():\n",
    "            G.edges[u,v]['time'] = random.randint(0,100)\n",
    "\n",
    "    all_graphs = [change_graph(grph,wp) for grph in class_graphs for _ in range(n_copies)]\n",
    "\n",
    "    label = [i for i in range(n_cluster) for _ in range(n_copies)]\n",
    "\n",
    "    Lw = []\n",
    "    for i in all_graphs:\n",
    "        Lw += [assign_weights(i)]\n",
    "\n",
    "    Lwe = []\n",
    "    for i in Lw:\n",
    "        Lwe += [adj_fillinf(i)]\n",
    "\n",
    "    # VR = VietorisRipsPersistence(metric=\"precomputed\")\n",
    "    # diagrams_trial = VR.fit_transform(Lwe)\n",
    "\n",
    "    input_diag_trial = []\n",
    "\n",
    "    # Trying Gudhi dimension 0 code\n",
    "    for Ad in tqdm(Lwe):\n",
    "        skeleton = gd.RipsComplex(distance_matrix=Ad, max_edge_length=2000)\n",
    "        simplex_tree = skeleton.create_simplex_tree(max_dimension=4)\n",
    "        barcode = simplex_tree.persistence()\n",
    "        # input_diag_trial.append(np.concatenate((simplex_tree.persistence_intervals_in_dimension(0),\n",
    "        #                                        simplex_tree.persistence_intervals_in_dimension(1),\n",
    "        #                                        simplex_tree.persistence_intervals_in_dimension(2)), axis=0))\n",
    "        input_diag_trial.append(simplex_tree.persistence_intervals_in_dimension(2))\n",
    "\n",
    "    # for diag in diagrams_trial:\n",
    "    #     input_diag_trial.append(np.delete(diag,-1,axis=1))\n",
    "\n",
    "    for i in range(n_cluster*n_copies):\n",
    "        input_diag_trial[i][input_diag_trial[i] == np.inf] = 10000\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_diag_trial, label, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_combined = (X_train + X_test)\n",
    "\n",
    "    print(f\"Sparsity : {sparsity}\")\n",
    "\n",
    "    print(\"Kernelization starts\")\n",
    "\n",
    "    # Scale Space Kernel\n",
    "\n",
    "    pssk = kernel_methods.PersistenceScaleSpaceKernel(bandwidth=1)\n",
    "\n",
    "    # Compute the kernel matrix for the combined data\n",
    "    pssk_matrix_combined = pssk.fit_transform(X_combined)\n",
    "\n",
    "    print(\"Kernelization ends\")\n",
    "    # Normalizing the matrix\n",
    "\n",
    "    # norm = np.linalg.norm(gram_matrix_combined.flatten())\n",
    "    # gram_matrix_combined = gram_matrix_combined / norm\n",
    "\n",
    "    # Split the kernel matrix into train and test parts\n",
    "    num_train = len(X_train)\n",
    "    pssk_matrix_train = pssk_matrix_combined[:num_train, :num_train]\n",
    "    pssk_matrix_test = pssk_matrix_combined[num_train:, :num_train]\n",
    "\n",
    "    # Weighted Gaussian Kernel\n",
    "\n",
    "    # pwgk = kernel_methods.PersistenceWeightedGaussianKernel(bandwidth=1)\n",
    "    # pwgk_matrix_combined = pwgk.fit_transform(X_combined)\n",
    "    # pwgk_matrix_train = pwgk_matrix_combined[:num_train, :num_train]\n",
    "    # pwgk_matrix_test = pwgk_matrix_combined[num_train:, :num_train]\n",
    "\n",
    "    print(\"Using Scale Space Kernel : \")\n",
    "    svm_output(pssk_matrix_train,pssk_matrix_test,y_train,y_test)\n",
    "    logistic_output(pssk_matrix_train,pssk_matrix_test,y_train,y_test)\n",
    "\n",
    "    # print(\"Using Weighted Gaussian Kernel : \")\n",
    "    # svm_output(pwgk_matrix_train,pwgk_matrix_test,y_train,y_test)\n",
    "    # logistic_output(pwgk_matrix_train,pwgk_matrix_test,y_train,y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 561.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9666666666666667\n",
      "Accuracy using Logistic Regression :  0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "test_results(50,1000,3,100,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 596.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9833333333333333\n",
      "Accuracy using Logistic Regression :  0.9666666666666667\n",
      "\n",
      "Run : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 580.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9333333333333333\n",
      "Accuracy using Logistic Regression :  0.95\n",
      "\n",
      "Run : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 548.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9666666666666667\n",
      "Accuracy using Logistic Regression :  0.95\n",
      "\n",
      "Run : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 470.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9666666666666667\n",
      "Accuracy using Logistic Regression :  0.95\n",
      "\n",
      "Run : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 517.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9333333333333333\n",
      "Accuracy using Logistic Regression :  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"\\nRun : {i}\")\n",
    "    test_results(50,1000,3,100,0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
