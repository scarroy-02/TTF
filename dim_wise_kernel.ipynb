{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gudhi as gd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from gudhi.representations import kernel_methods\n",
    "import networkx as nx\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_output(mat_train,mat_test,y_train,y_test):\n",
    "    # Using SVM\n",
    "\n",
    "    svm_classifier = SVC(kernel='precomputed')\n",
    "    svm_classifier.fit(mat_train, y_train)\n",
    "\n",
    "    # y_pred = svm_classifier.predict(mat_test)\n",
    "\n",
    "    accuracy = svm_classifier.score(mat_test, y_test)\n",
    "    print(\"Accuracy using SVM : \", accuracy)\n",
    "    return accuracy\n",
    "    # print(classification_report(y_test,y_pred))\n",
    "\n",
    "def logistic_output(mat_train,mat_test,y_train,y_test):\n",
    "\n",
    "    # Using logistic regression\n",
    "\n",
    "    klr = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "    klr.kernel = 'precomputed'\n",
    "\n",
    "    klr.fit(mat_train,y_train)\n",
    "\n",
    "    # y_pred = klr.predict(mat_test)\n",
    "\n",
    "    accuracy = klr.score(mat_test, y_test)\n",
    "    print(\"Accuracy using Logistic Regression : \", accuracy)\n",
    "    return accuracy\n",
    "\n",
    "    # print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_testing(v,e,n_cluster,n_copies,wp,pers_dim):\n",
    "\n",
    "    # Calculate sparsity\n",
    "    sparsity = 2 * e / (v * (v + 1))\n",
    "    print(f\"Sparsity : {sparsity}\")\n",
    "\n",
    "    # Generate class graphs and assign random times to edges\n",
    "    class_graphs = [nx.gnm_random_graph(v, e) for _ in range(n_cluster)]\n",
    "    for G in class_graphs:\n",
    "        for (u, v) in G.edges():\n",
    "            G.edges[u, v]['time'] = random.randint(0, 100)\n",
    "\n",
    "    # Apply change_graph function in parallel\n",
    "    all_graphs = Parallel(n_jobs=-1)(delayed(change_graph)(grph, wp) for grph in class_graphs for _ in range(n_copies))\n",
    "\n",
    "    # Generate labels\n",
    "    label = [i for i in range(n_cluster) for _ in range(n_copies)]\n",
    "\n",
    "    # Apply assign_weights function in parallel\n",
    "    Lw = Parallel(n_jobs=-1)(delayed(assign_weights)(i) for i in all_graphs)\n",
    "\n",
    "    # Apply adj_fillinf function in parallel\n",
    "    Lwe = Parallel(n_jobs=-1)(delayed(adj_fillinf)(i) for i in Lw)\n",
    "\n",
    "    input_diag_trial = []\n",
    "\n",
    "    # Trying Gudhi dimension-wise\n",
    "    for Ad in tqdm(Lwe):\n",
    "        skeleton = gd.RipsComplex(distance_matrix=Ad, max_edge_length=2000)\n",
    "        simplex_tree = skeleton.create_simplex_tree(max_dimension=pers_dim+2)\n",
    "        barcode = simplex_tree.persistence()\n",
    "        input_diag_trial.append(simplex_tree.persistence_intervals_in_dimension(pers_dim))\n",
    "\n",
    "    for i in range(n_cluster*n_copies):\n",
    "        input_diag_trial[i][input_diag_trial[i] == np.inf] = 10000\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_diag_trial, label, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_combined = (X_train + X_test)\n",
    "\n",
    "    # Write the diagrams to a file\n",
    "    with open('persistent_diagrams.txt', 'w') as f:\n",
    "        for diagram in X_combined:\n",
    "            np.savetxt(f, diagram, fmt='%.2f')\n",
    "            f.write('\\n')\n",
    "\n",
    "    print(\"Persistence diagrams file written\")\n",
    "\n",
    "    def compute_kernel_matrix():\n",
    "        # Call the C++ program\n",
    "        result = subprocess.run(['./kmp'], check=True)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise Exception(\"C++ program failed to run.\")\n",
    "        \n",
    "        # Load the kernel matrix from the CSV file\n",
    "        kernel_matrix = np.loadtxt('kernel_matrix.csv', delimiter=',')\n",
    "        return kernel_matrix\n",
    "    \n",
    "    # Compute the kernel matrix using the C++ program\n",
    "    pssk_matrix_combined = compute_kernel_matrix()\n",
    "\n",
    "    print(\"Kernelization complete\")\n",
    "\n",
    "    # Split the kernel matrix into train and test parts\n",
    "    num_train = len(X_train)\n",
    "    pssk_matrix_train = pssk_matrix_combined[:num_train, :num_train]\n",
    "    pssk_matrix_test = pssk_matrix_combined[num_train:, :num_train]\n",
    "\n",
    "    # Weighted Gaussian Kernel\n",
    "\n",
    "    # pwgk = kernel_methods.PersistenceWeightedGaussianKernel(bandwidth=1)\n",
    "    # pwgk_matrix_combined = pwgk.fit_transform(X_combined)\n",
    "    # pwgk_matrix_train = pwgk_matrix_combined[:num_train, :num_train]\n",
    "    # pwgk_matrix_test = pwgk_matrix_combined[num_train:, :num_train]\n",
    "\n",
    "    print(\"Using Scale Space Kernel\")\n",
    "    return svm_output(pssk_matrix_train,pssk_matrix_test,y_train,y_test), logistic_output(pssk_matrix_train,pssk_matrix_test,y_train,y_test)\n",
    "\n",
    "    # print(\"Using Weighted Gaussian Kernel : \")\n",
    "    # svm_output(pwgk_matrix_train,pwgk_matrix_test,y_train,y_test)\n",
    "    # logistic_output(pwgk_matrix_train,pwgk_matrix_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 471.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence diagrams file written\n",
      "Reading complete\n",
      "Time taken: 0.0297973 seconds\n",
      "Kernelization complete\n",
      "Time taken: 14.4669 seconds\n",
      "Kernelization complete\n",
      "Using Scale Space Kernel\n",
      "Accuracy using SVM :  0.8\n",
      "Accuracy using Logistic Regression :  0.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8, 0.8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_testing(50,1000,3,100,0.05,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(v, e, n_clusters_list, n_copies, wp_list, pers_dim, n_runs=5):\n",
    "    results = []\n",
    "\n",
    "    for n_cluster in n_clusters_list:\n",
    "        for wp in wp_list:\n",
    "            svm_accuracies = []\n",
    "            logistic_accuracies = []\n",
    "            \n",
    "            for _ in range(n_runs):\n",
    "                svm_accuracy, logistic_accuracy = new_testing(v, e, n_cluster, n_copies, wp, pers_dim)\n",
    "                svm_accuracies.append(svm_accuracy)\n",
    "                logistic_accuracies.append(logistic_accuracy)\n",
    "            \n",
    "            svm_avg_accuracy = np.mean(svm_accuracies)\n",
    "            svm_std_accuracy = np.std(svm_accuracies)\n",
    "            logistic_avg_accuracy = np.mean(logistic_accuracies)\n",
    "            logistic_std_accuracy = np.std(logistic_accuracies)\n",
    "            \n",
    "            results.append((n_cluster, wp*100, svm_avg_accuracy, svm_std_accuracy, logistic_avg_accuracy, logistic_std_accuracy))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 511.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence diagrams file written\n",
      "Reading complete\n",
      "Time taken: 0.0307848 seconds\n",
      "Kernelization complete\n",
      "Time taken: 12.7391 seconds\n",
      "Kernelization complete\n",
      "Using Scale Space Kernel\n",
      "Accuracy using SVM :  0.9833333333333333\n",
      "Accuracy using Logistic Regression :  0.9666666666666667\n",
      "Sparsity : 0.7843137254901961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 458.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence diagrams file written\n",
      "Reading complete\n",
      "Time taken: 0.0289101 seconds\n",
      "Kernelization complete\n",
      "Time taken: 12.172 seconds\n",
      "Kernelization complete\n",
      "Using Scale Space Kernel\n",
      "Accuracy using SVM :  0.9833333333333333\n",
      "Accuracy using Logistic Regression :  1.0\n",
      "Sparsity : 0.7843137254901961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 455.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persistence diagrams file written\n",
      "Reading complete\n",
      "Time taken: 0.0322593 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m n_runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Run experiments\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_clusters_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_copies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwp_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpers_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_runs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n\u001b[1;32m     14\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClasses\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerturbation \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM Avg Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM StdDev\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic Avg Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic StdDev\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m, in \u001b[0;36mrun_experiments\u001b[0;34m(v, e, n_clusters_list, n_copies, wp_list, pers_dim, n_runs)\u001b[0m\n\u001b[1;32m      7\u001b[0m logistic_accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_runs):\n\u001b[0;32m---> 10\u001b[0m     svm_accuracy, logistic_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mnew_testing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_copies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpers_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     svm_accuracies\u001b[38;5;241m.\u001b[39mappend(svm_accuracy)\n\u001b[1;32m     12\u001b[0m     logistic_accuracies\u001b[38;5;241m.\u001b[39mappend(logistic_accuracy)\n",
      "Cell \u001b[0;32mIn[17], line 61\u001b[0m, in \u001b[0;36mnew_testing\u001b[0;34m(v, e, n_cluster, n_copies, wp, pers_dim)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m kernel_matrix\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Compute the kernel matrix using the C++ program\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m pssk_matrix_combined \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_kernel_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKernelization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Split the kernel matrix into train and test parts\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 51\u001b[0m, in \u001b[0;36mnew_testing.<locals>.compute_kernel_matrix\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_kernel_matrix\u001b[39m():\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Call the C++ program\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./kmp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC++ program failed to run.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/TDA/lib/python3.8/subprocess.py:495\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    497\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/TDA/lib/python3.8/subprocess.py:1020\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/TDA/lib/python3.8/subprocess.py:1083\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/TDA/lib/python3.8/subprocess.py:1822\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1821\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1822\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1823\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1824\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/TDA/lib/python3.8/subprocess.py:1780\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1780\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "v = 50\n",
    "e = 1000\n",
    "n_clusters_list = [3, 5, 7, 9]\n",
    "n_copies = 100\n",
    "wp_list = [0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10]\n",
    "pers_dim = 2\n",
    "n_runs = 5\n",
    "\n",
    "# Run experiments\n",
    "results = run_experiments(v, e, n_clusters_list, n_copies, wp_list, pers_dim, n_runs)\n",
    "\n",
    "# Create DataFrame\n",
    "columns = ['Classes', 'Perturbation %', 'SVM Avg Accuracy', 'SVM StdDev', 'Logistic Avg Accuracy', 'Logistic StdDev']\n",
    "df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "# Use tabulate to format the DataFrame as a Markdown table\n",
    "markdown_table = tabulate(df, headers='keys', tablefmt='pipe', showindex=False)\n",
    "\n",
    "# Write the table to a text file\n",
    "with open('experiment_results.md', 'w') as f:\n",
    "    f.write(markdown_table)\n",
    "\n",
    "print(\"Results have been written to experiment_results.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def test_results(v,e,n_cluster,n_copies,wp):\n",
    "    sparsity = 2 * e / (v * (v + 1))\n",
    "\n",
    "    class_graphs = [nx.gnm_random_graph(v,e) for _ in range(n_cluster)]\n",
    "    for G in class_graphs:\n",
    "        for (u,v) in G.edges():\n",
    "            G.edges[u,v]['time'] = random.randint(0,100)\n",
    "\n",
    "    all_graphs = [change_graph(grph,wp) for grph in class_graphs for _ in range(n_copies)]\n",
    "\n",
    "    label = [i for i in range(n_cluster) for _ in range(n_copies)]\n",
    "\n",
    "    Lw = []\n",
    "    for i in all_graphs:\n",
    "        Lw += [assign_weights(i)]\n",
    "\n",
    "    Lwe = []\n",
    "    for i in Lw:\n",
    "        Lwe += [adj_fillinf(i)]\n",
    "\n",
    "    # VR = VietorisRipsPersistence(metric=\"precomputed\")\n",
    "    # diagrams_trial = VR.fit_transform(Lwe)\n",
    "\n",
    "    input_diag_trial = []\n",
    "\n",
    "    # Trying Gudhi dimension 0 code\n",
    "    for Ad in tqdm(Lwe):\n",
    "        skeleton = gd.RipsComplex(distance_matrix=Ad, max_edge_length=2000)\n",
    "        simplex_tree = skeleton.create_simplex_tree(max_dimension=4)\n",
    "        barcode = simplex_tree.persistence()\n",
    "        # input_diag_trial.append(np.concatenate((simplex_tree.persistence_intervals_in_dimension(0),\n",
    "        #                                        simplex_tree.persistence_intervals_in_dimension(1),\n",
    "        #                                        simplex_tree.persistence_intervals_in_dimension(2)), axis=0))\n",
    "        input_diag_trial.append(simplex_tree.persistence_intervals_in_dimension(2))\n",
    "\n",
    "    # for diag in diagrams_trial:\n",
    "    #     input_diag_trial.append(np.delete(diag,-1,axis=1))\n",
    "\n",
    "    for i in range(n_cluster*n_copies):\n",
    "        input_diag_trial[i][input_diag_trial[i] == np.inf] = 10000\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_diag_trial, label, test_size=0.2, random_state=42)\n",
    "\n",
    "    X_combined = (X_train + X_test)\n",
    "\n",
    "    print(f\"Sparsity : {sparsity}\")\n",
    "\n",
    "    print(\"Kernelization starts\")\n",
    "\n",
    "    # Scale Space Kernel\n",
    "\n",
    "    pssk = kernel_methods.PersistenceScaleSpaceKernel(bandwidth=1)\n",
    "\n",
    "    # Compute the kernel matrix for the combined data\n",
    "    pssk_matrix_combined = pssk.fit_transform(X_combined)\n",
    "\n",
    "    print(\"Kernelization ends\")\n",
    "    # Normalizing the matrix\n",
    "\n",
    "    # norm = np.linalg.norm(gram_matrix_combined.flatten())\n",
    "    # gram_matrix_combined = gram_matrix_combined / norm\n",
    "\n",
    "    # Split the kernel matrix into train and test parts\n",
    "    num_train = len(X_train)\n",
    "    pssk_matrix_train = pssk_matrix_combined[:num_train, :num_train]\n",
    "    pssk_matrix_test = pssk_matrix_combined[num_train:, :num_train]\n",
    "\n",
    "    # Weighted Gaussian Kernel\n",
    "\n",
    "    # pwgk = kernel_methods.PersistenceWeightedGaussianKernel(bandwidth=1)\n",
    "    # pwgk_matrix_combined = pwgk.fit_transform(X_combined)\n",
    "    # pwgk_matrix_train = pwgk_matrix_combined[:num_train, :num_train]\n",
    "    # pwgk_matrix_test = pwgk_matrix_combined[num_train:, :num_train]\n",
    "\n",
    "    print(\"Using Scale Space Kernel : \")\n",
    "    svm_output(pssk_matrix_train,pssk_matrix_test,y_train,y_test)\n",
    "    logistic_output(pssk_matrix_train,pssk_matrix_test,y_train,y_test)\n",
    "\n",
    "    # print(\"Using Weighted Gaussian Kernel : \")\n",
    "    # svm_output(pwgk_matrix_train,pwgk_matrix_test,y_train,y_test)\n",
    "    # logistic_output(pwgk_matrix_train,pwgk_matrix_test,y_train,y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 561.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9666666666666667\n",
      "Accuracy using Logistic Regression :  0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "test_results(50,1000,3,100,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 596.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9833333333333333\n",
      "Accuracy using Logistic Regression :  0.9666666666666667\n",
      "\n",
      "Run : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 580.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9333333333333333\n",
      "Accuracy using Logistic Regression :  0.95\n",
      "\n",
      "Run : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 548.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9666666666666667\n",
      "Accuracy using Logistic Regression :  0.95\n",
      "\n",
      "Run : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 470.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9666666666666667\n",
      "Accuracy using Logistic Regression :  0.95\n",
      "\n",
      "Run : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 517.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity : 0.7843137254901961\n",
      "Kernelization starts\n",
      "Kernelization ends\n",
      "Using Scale Space Kernel : \n",
      "Accuracy using SVM :  0.9333333333333333\n",
      "Accuracy using Logistic Regression :  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"\\nRun : {i}\")\n",
    "    test_results(50,1000,3,100,0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
